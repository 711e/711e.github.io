---
layout: post
title:  "Machine Learning"
crawlertitle: "Machine Learning"
summary: "Machine Learning"
date:   2019-04-24 10:37:00 +0700
categories: posts
tags: ['Machine Learning']
author: 711E
---

### 一、机器学习
#### 1.线性回归

变量之间的对应函数关系
##### (1)函数模型
`h(x)=w0+w1x1+w2x2+...+wnxn`
`h(x)=WX`
##### (2)损失函数
最小二乘法：我们有很多的给定点，这时候我们需要找出一条线去拟合它，那么我先假设这个线的方程，然后把数据点代入假设的方程得到观测值，求使得实际值与观测值相减的平方和最小的参数。对变量求偏导联立便可求。

#### 2.逻辑回归

sigmoid

#### 3.朴素贝叶斯

假设有一个数据集，由两类组成（简化问题），对于每个样本的分类，我们都已经知晓。现在出现一个新的点new_point (x,y)，其分类未知。我们可以用p1(x,y)表示数据点(x,y)属于红色一类的概率，同时也可以用p2(x,y)表示数据点(x,y)属于蓝色一类的概率。那要把new_point归在红、蓝哪一类呢？

我们提出这样的规则：
 * 如果p1(x,y) > p2(x,y)，则(x,y)为红色一类。
 * 如果p1(x,y) <p2(x,y),  则(x,y)为蓝色一类。

#### 4.决策树

用决策树分类：从根节点开始，对实例的某一特征进行测试，根据测试结果将实例分配到其子节点，此时每个子节点对应着该特征的一个取值，如此递归的对实例进行测试并分配，直到到达叶节点，最后将实例分到叶节点的类中。
* 决策树学习的目标：根据给定的训练数据集构建一个决策树模型，使它能够对实例进行正确的分类。
* 决策树学习的本质：从训练集中归纳出一组分类规则，或者说是由训练数据集估计条件概率模型。
* 决策树学习的损失函数：正则化的极大似然函数
* 决策树学习的测试：最小化损失函数
* 决策树学习的目标：在损失函数的意义下，选择最优决策树的问题

#### 5.GBDT

GBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预测值后能得真实值的累加量。比如A的真实年龄是18岁，但第一棵树的预测年龄是12岁，差了6岁，即残差为6岁。那么在第二棵树里我们把A的年龄设为6岁去学习，如果第二棵树真的能把A分到6岁的叶子节点，那累加两棵树的结论就是A的真实年龄；如果第二棵树的结论是5岁，则A仍然存在1岁的残差，第三棵树里A的年龄就变成1岁，继续学。

#### 6.随机森林

每棵树的按照如下规则生成：

1. 如果训练集大小为N，对于每棵树而言，随机且有放回地从训练集中的抽取N个训练样本（这种采样方式称为bootstrap sample方法），作为该树的训练集；从这里我们可以知道：每棵树的训练集都是不同的，而且里面包含重复的训练样本（理解这点很重要）。

**为什么要随机抽样训练集？**

如果不进行随机抽样，每棵树的训练集都一样，那么最终训练出的树分类结果也是完全一样的，这样的话完全没有bagging的必要；

**为什么要有放回地抽样？**

如果不是有放回的抽样，那么每棵树的训练样本都是不同的，都是没有交集的，这样每棵树都是"有偏的"，都是绝对"片面的"（当然这样说可能不对），也就是说每棵树训练出来都是有很大的差异的；而随机森林最后分类取决于多棵树（弱分类器）的投票表决，这种表决应该是"求同"，因此使用完全不同的训练集来训练每棵树这样对最终分类结果是没有帮助的，这样无异于是"盲人摸象"。

2. 如果每个样本的特征维度为M，指定一个常数m<<M，随机地从M个特征中选取m个特征子集，每次树进行分裂时，从这m个特征中选择最优的；

3. 每棵树都尽最大程度的生长，并且没有剪枝过程。
　　一开始我们提到的随机森林中的“随机”就是指的这里的两个随机性。两个随机性的引入对随机森林的分类性能至关重要。由于它们的引入，使得随机森林不容易陷入过拟合，并且具有很好得抗噪能力（比如：对缺省值不敏感）。

**随机森林分类效果（错误率）与两个因素有关：**

* 森林中任意两棵树的相关性：相关性越大，错误率越大；
* 森林中每棵树的分类能力：每棵树的分类能力越强，整个森林的错误率越低。
减小特征选择个数m，树的相关性和分类能力也会相应的降低；增大m，两者也会随之增大。所以关键问题是如何选择最优的m（或者是范围），这也是随机森林唯一的一个参数。

#### 7.Adaboosting

AdaBoost是典型的Boosting算法，属于Boosting家族的一员。在说AdaBoost之前，先说说Boosting提升算法。Boosting算法是将“弱学习算法“提升为“强学习算法”的过程，主要思想是“三个臭皮匠顶个诸葛亮”。一般来说，找到弱学习算法要相对容易一些，然后通过反复学习得到一系列弱分类器，组合这些弱分类器得到一个强分类器。Boosting算法要涉及到两个部分，加法模型和前向分步算法。加法模型就是说强分类器由一系列弱分类器线性相加而成。一般组合形式如下：
`FM(x;P)=∑m=1nβmh(x;am)`其中，h(x;am)就是一个个的弱分类器，am是弱分类器学习到的最优参数，βm就是弱学习在强分类器中所占比重，P是所有am和βm的组合。这些弱分类器线性相加组成强分类器。
前向分步就是说在训练过程中，下一轮迭代产生的分类器是在上一轮的基础上训练得来的。也就是可以写成这样的形式：`Fm(x)=Fm−1(x)+βmhm(x;am)`由于采用的损失函数不同，Boosting算法也因此有了不同的类型，AdaBoost就是损失函数为指数损失的Boosting算法。

**基于Boosting的理解，对于AdaBoost，我们要搞清楚两点：**
* 每一次迭代的弱学习h(x;am)有何不一样，如何学习？
* 弱分类器权值βm如何确定？
对于第一个问题，AdaBoost改变了训练数据的权值，也就是样本的概率分布，其思想是将关注点放在被错误分类的样本上，减小上一轮被正确分类的样本权值，提高那些被错误分类的样本权值。然后，再根据所采用的一些基本机器学习算法进行学习，比如逻辑回归。

对于第二个问题，AdaBoost采用加权多数表决的方法，加大分类误差率小的弱分类器的权重，减小分类误差率大的弱分类器的权重。这个很好理解，正确率高分得好的弱分类器在强分类器中当然应该有较大的发言权。
迭代t次：
1. 初始化D1=(w11,…，w1i,…，w1N)，w1i=1/N,i=1,2,…，N,给定一个二分类的训练数据集：T=(x1,y1),(x2,y2),……,(xN,yN),标记yi∈[−1,1],得到弱分类器Gt(x)
2. 分类误差et=P(Gt(x)!=yi)
3. Gt(x)的权值αt=1/2·log(1-et)/et,et≤1/2时，αt>0,并且随着et的减小而增大，也就是说分类误差越小分类器的权值越大，这里还可以看出可以看出权值分布Dt通过影响et来影响了αt，这是Dt的第一个影响。
4. 更新权值分布Dt+1(x)
得到强分类器：F(x)=sign(i~t∑(αtGt(x)))

#### 8.SVM

**核函数** 的基本作用就是接受两个低维空间里的向量，能够计算出经过某个变换后在高维空间里的向量内积值。几个比较常用的核函数
1. 既然有很多的核函数，针对具体问题该怎么选择？
2. 如果使用核函数向高维空间映射后，问题仍然是线性不可分的，那怎么办？
第一个问题现在就可以回答你：对核函数的选择，现在还缺乏指导原则！各种实验的观察结果（不光是文本分类）的确表明，某些问题用某些核函数效果很好，用另一些就很差，但是一般来讲，径向基核函数是不会出太大偏差的一种，首选。（我做文本分类系统的时候，使用径向基核函数，没有参数调优的情况下，绝大部分类别的准确和召回都在85%以上，可见。虽然libSVM的作者林智仁认为文本分类用线性核函数效果更佳，待考证）
对第二个问题的解决则引出了我们下一节的主题：松弛变量。
**松弛变量** 是非负的，因此最终的结果是要求间隔可以比1小。但是当某些点出现这种间隔比1小的情况时（这些点也叫离群点），意味着我们放弃了对这些点的精确分类，而这对我们的分类器来说是种损失。但是放弃这些点也带来了好处，那就是使分类面不必向这些点的方向移动，因而可以得到更大的几何间隔（在低维空间看来，分类边界也更平滑）。显然我们必须权衡这种损失和好处。好处很明显，我们得到的分类间隔越大，好处就越多。
这个式子有这么几点要注意：
1. 并非所有的样本点都有一个松弛变量与其对应。实际上只有“离群点”才有，或者也可以这么看，所有没离群的点松弛变量都等于0（对负类来说，离群点就是在前面图中，跑到H2右侧的那些负样本点，对正类来说，就是跑到H1左侧的那些正样本点），在迭代求w的时候如何样本点非离群点，即分类正确，那么就设它的松弛变量为0
2. 松弛变量的值实际上标示出了对应的点到底离群有多远，值越大，点就越远。
3. 惩罚因子C决定了你有多重视离群点带来的损失，显然当所有离群点的松弛变量的和一定时，你定的C越大，对目标函数的损失也越大，此时就暗示着你非常不愿意放弃这些离群点，最极端的情况是你把C定为无限大，这样只要稍有一个点离群，目标函数的值马上变成无限大，马上让问题变成无解，这就退化成了硬间隔问题。
4. 惩罚因子C不是一个变量，整个优化问题在解的时候，C是一个你必须事先指定的值，指定这个值以后，解一下，得到一个分类器，然后用测试数据看看结果怎么样，如果不够好，换一个C的值，再解一次优化问题，得到另一个分类器，再看看效果，如此就是一个参数寻优的过程，但这和优化问题本身决不是一回事，优化问题在解的过程中，C一直是定值，要记住。
五是尽管加了松弛变量这么一说，但这个优化问题仍然是一个优化问题（汗，这不废话么），解它的过程比起原始的硬间隔问题来说，没有任何更加特殊的地方。
